{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os.path\n",
    "\n",
    "# from google.auth.transport.requests import Request\n",
    "# from google.oauth2.credentials import Credentials\n",
    "# from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "# from googleapiclient.discovery import build\n",
    "# from googleapiclient.errors import HttpError\n",
    "\n",
    "# # If modifying these scopes, delete the file token.json.\n",
    "# SCOPES = [\"https://www.googleapis.com/auth/youtube.readonly\",\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "\n",
    "\n",
    "# creds = None\n",
    "# # The file token.json stores the user's access and refresh tokens, and is\n",
    "# # created automatically when the authorization flow completes for the first\n",
    "# # time.\n",
    "# if os.path.exists(\"token.json\"):\n",
    "#   creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "# # If there are no (valid) credentials available, let the user log in.\n",
    "# if not creds or not creds.valid:\n",
    "#   if creds and creds.expired and creds.refresh_token:\n",
    "#     creds.refresh(Request())\n",
    "#   else:\n",
    "#     flow = InstalledAppFlow.from_client_secrets_file(\n",
    "#         \"credentials.json\", SCOPES\n",
    "#     )\n",
    "#     creds = flow.run_local_server(port=0)\n",
    "#   # Save the credentials for the next run\n",
    "#   with open(\"token.json\", \"w\") as token:\n",
    "#     token.write(creds.to_json())\n",
    "\n",
    "# try:\n",
    "#   youtube = build(\"youtube\", \"v3\", credentials=creds)\n",
    "\n",
    "#       # Taking input from the user and slicing for video id\n",
    "#   video_id = input('Enter Youtube Video URL: ')[-11:]\n",
    "#   print(\"video id: \" + video_id)\n",
    "  \n",
    "#   # Getting the channelId of the video uploader\n",
    "#   video_response = youtube.videos().list(\n",
    "#       part='snippet',\n",
    "#       id=video_id\n",
    "#   ).execute()\n",
    "  \n",
    "#   print(video_response)\n",
    "#   # Splitting the response for channelID\n",
    "#   video_snippet = video_response['items'][0]['snippet']\n",
    "#   uploader_channel_id = video_snippet['channelId']\n",
    "#   print(\"channel id: \" + uploader_channel_id)\n",
    "  \n",
    "# except HttpError as err:\n",
    "#   print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video id: Pv0iVoSZzN8\n",
      "Video Response: {'kind': 'youtube#videoListResponse', 'etag': 'wBOw43Neh-kQLqMfCKOqLW-OJFE', 'items': [{'kind': 'youtube#video', 'etag': 'pufOP10W29zOstMUtY5vf8fP9cY', 'id': 'Pv0iVoSZzN8', 'snippet': {'publishedAt': '2024-04-27T16:00:00Z', 'channelId': 'UCX6OQ3DkcsbYNE6H8uQQuVA', 'title': 'In 10 Minutes This Room Will Explode!', 'description': 'I didn’t expect that to happen…\\nThere’s no jumping through hoops (or plate glass windows) with T-Mobile. Customers can get Magenta Status from day one, including hotel discounts on select brands, deals on rental cars, discounts on select concert tickets nationwide, and so much more. See how at https://t-mobile.com/status\\n\\nNew Merch - https://mrbeast.store\\n\\nCheck out Viewstats! - https://www.viewstats.com/\\n\\nSUBSCRIBE OR I TAKE YOUR DOG\\n╔═╦╗╔╦╗╔═╦═╦╦╦╦╗╔═╗\\n║╚╣║║║╚╣╚╣╔╣╔╣║╚╣═╣ \\n╠╗║╚╝║║╠╗║╚╣║║║║║═╣\\n╚═╩══╩═╩═╩═╩╝╚╩═╩═╝\\n\\nFor any questions or inquiries regarding this video, please reach out to chucky@mrbeastbusiness.com\\n\\nMusic Provided by https://www.extrememusic.com\\n\\n----------------------------------------------------------------\\nfollow all of these or i will kick you\\n• Facebook - https://www.facebook.com/MrBeast6000/\\n• Twitter - https://twitter.com/MrBeast\\n•  Instagram - https://www.instagram.com/mrbeast\\n•  Im Hiring! - https://www.mrbeastjobs.com/\\n--------------------------------------------------------------------', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/Pv0iVoSZzN8/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/Pv0iVoSZzN8/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/Pv0iVoSZzN8/hqdefault.jpg', 'width': 480, 'height': 360}, 'standard': {'url': 'https://i.ytimg.com/vi/Pv0iVoSZzN8/sddefault.jpg', 'width': 640, 'height': 480}, 'maxres': {'url': 'https://i.ytimg.com/vi/Pv0iVoSZzN8/maxresdefault.jpg', 'width': 1280, 'height': 720}}, 'channelTitle': 'MrBeast', 'categoryId': '24', 'liveBroadcastContent': 'none', 'defaultLanguage': 'en', 'localized': {'title': 'In 10 Minutes This Room Will Explode!', 'description': 'I didn’t expect that to happen…\\nThere’s no jumping through hoops (or plate glass windows) with T-Mobile. Customers can get Magenta Status from day one, including hotel discounts on select brands, deals on rental cars, discounts on select concert tickets nationwide, and so much more. See how at https://t-mobile.com/status\\n\\nNew Merch - https://mrbeast.store\\n\\nCheck out Viewstats! - https://www.viewstats.com/\\n\\nSUBSCRIBE OR I TAKE YOUR DOG\\n╔═╦╗╔╦╗╔═╦═╦╦╦╦╗╔═╗\\n║╚╣║║║╚╣╚╣╔╣╔╣║╚╣═╣ \\n╠╗║╚╝║║╠╗║╚╣║║║║║═╣\\n╚═╩══╩═╩═╩═╩╝╚╩═╩═╝\\n\\nFor any questions or inquiries regarding this video, please reach out to chucky@mrbeastbusiness.com\\n\\nMusic Provided by https://www.extrememusic.com\\n\\n----------------------------------------------------------------\\nfollow all of these or i will kick you\\n• Facebook - https://www.facebook.com/MrBeast6000/\\n• Twitter - https://twitter.com/MrBeast\\n•  Instagram - https://www.instagram.com/mrbeast\\n•  Im Hiring! - https://www.mrbeastjobs.com/\\n--------------------------------------------------------------------'}, 'defaultAudioLanguage': 'en'}}], 'pageInfo': {'totalResults': 1, 'resultsPerPage': 1}}\n",
      "channel id: UCX6OQ3DkcsbYNE6H8uQQuVA\n",
      "Fetching Comments...\n",
      "['❤او', 'No', 'MrBeast eu sou fã de você', 'Nice व्हिडीओ सर जी', '❤❤❤❤ tuyệt vời ❤❤❤❤']\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import re\n",
    "\n",
    "API_KEY = ''  # Put in your API Key\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)  # initializing Youtube API\n",
    "\n",
    "# Improved input handling for video ID\n",
    "def extract_video_id(url):\n",
    "    match = re.search(r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*', url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "video_url = input('Enter YouTube Video URL: ')\n",
    "video_id = extract_video_id(video_url)\n",
    "\n",
    "if not video_id:\n",
    "    print(\"Invalid YouTube URL\")\n",
    "else:\n",
    "    print(\"video id: \" + video_id)\n",
    "\n",
    "    # Getting the channelId of the video uploader\n",
    "    try:\n",
    "        video_response = youtube.videos().list(\n",
    "            part='snippet',\n",
    "            id=video_id\n",
    "        ).execute()\n",
    "\n",
    "        print(\"Video Response:\", video_response)  # Debugging step\n",
    "\n",
    "        if 'items' in video_response and video_response['items']:\n",
    "            video_snippet = video_response['items'][0]['snippet']\n",
    "            uploader_channel_id = video_snippet.get('channelId', 'No channelId found')\n",
    "            print(\"channel id: \" + uploader_channel_id)\n",
    "\n",
    "            # Fetch comments\n",
    "            print(\"Fetching Comments...\")\n",
    "            comments = []\n",
    "            nextPageToken = None\n",
    "            while len(comments) < 600:\n",
    "                request = youtube.commentThreads().list(\n",
    "                    part='snippet',\n",
    "                    videoId=video_id,\n",
    "                    maxResults=100,  # You can fetch up to 100 comments per request\n",
    "                    pageToken=nextPageToken\n",
    "                )\n",
    "                response = request.execute()\n",
    "                for item in response['items']:\n",
    "                    comment = item['snippet']['topLevelComment']['snippet']\n",
    "                    # Check if the comment is not from the video uploader\n",
    "                    if comment['authorChannelId']['value'] != uploader_channel_id:\n",
    "                        comments.append(comment['textDisplay'])\n",
    "                nextPageToken = response.get('nextPageToken')\n",
    "\n",
    "                if not nextPageToken:\n",
    "                    break\n",
    "            # Print the first 5 comments\n",
    "            print(comments[:5])\n",
    "\n",
    "        else:\n",
    "            print(\"No video found for the provided ID.\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel to CsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "\n",
    "# Get the channel name and upload playlist ID\n",
    "def get_channel_info(channel_id):\n",
    "    response = youtube.channels().list(\n",
    "        part='snippet,contentDetails',\n",
    "        id=channel_id\n",
    "    ).execute()\n",
    "    if 'items' in response and len(response['items']) > 0:\n",
    "        channel = response['items'][0]['snippet']['title']\n",
    "        upload_playlist_id = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "        return channel, upload_playlist_id\n",
    "    return None, None\n",
    "\n",
    "# Fetch 100 video IDs from the uploads playlist\n",
    "def get_video_ids_from_channel(upload_playlist_id, max_results=100):\n",
    "    video_ids = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(video_ids) < max_results:\n",
    "        response = youtube.playlistItems().list(\n",
    "            part='snippet',\n",
    "            playlistId=upload_playlist_id,\n",
    "            maxResults=50,  # API allows max 50 results per request\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "        \n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['snippet']['resourceId']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token or len(video_ids) >= max_results:\n",
    "            break\n",
    "    \n",
    "    return video_ids[:max_results]\n",
    "\n",
    "# Fetch the video title\n",
    "def get_video_title(video_id):\n",
    "    response = youtube.videos().list(\n",
    "        part='snippet',\n",
    "        id=video_id\n",
    "    ).execute()\n",
    "    if 'items' in response and len(response['items']) > 0:\n",
    "        return response['items'][0]['snippet']['title']\n",
    "    return None\n",
    "\n",
    "# Fetch comments for a video\n",
    "def get_comments(video_id, max_comments=100):\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(comments) < max_comments:\n",
    "        response = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            maxResults=100,  # Fetch up to 100 comments per request\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(comment)\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token or len(comments) >= max_comments:\n",
    "            break\n",
    "\n",
    "    return comments[:max_comments]\n",
    "\n",
    "# Write the data to a CSV file\n",
    "def write_to_csv(channel_name, video_data):\n",
    "    with open(f'{channel_name}_video_comments.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Channel Name\", \"Video Title\", \"Comment\"])\n",
    "        \n",
    "        for video_title, comments in video_data.items():\n",
    "            for comment in comments:\n",
    "                writer.writerow([channel_name, video_title, comment])\n",
    "\n",
    "# Main Function\n",
    "def fetch_videos_and_comments(channel_id, max_videos=100, max_comments_per_video=100):\n",
    "    # Get channel information\n",
    "    channel_name, upload_playlist_id = get_channel_info(channel_id)\n",
    "    \n",
    "    if not channel_name or not upload_playlist_id:\n",
    "        print(\"Invalid channel ID or channel information not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Fetching data for channel: {channel_name}\")\n",
    "\n",
    "    # Get video IDs\n",
    "    video_ids = get_video_ids_from_channel(upload_playlist_id, max_results=max_videos)\n",
    "\n",
    "    video_data = {}\n",
    "\n",
    "    # For each video, get the title and comments\n",
    "    for video_id in video_ids:\n",
    "        video_title = get_video_title(video_id)\n",
    "        if video_title:\n",
    "            print(f\"Fetching comments for video: {video_title}\")\n",
    "            comments = get_comments(video_id, max_comments=max_comments_per_video)\n",
    "            video_data[video_title] = comments\n",
    "\n",
    "    # Write all data to a CSV\n",
    "    write_to_csv(channel_name, video_data)\n",
    "    print(f\"Data saved to {channel_name}_video_comments.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel to Csv threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for channel: MrBeast\n",
      "Fetching comments for video: Running With Bigger And Bigger Lunchlys\n",
      "Fetching comments for video: Holding Bigger And Bigger Dogs\n",
      "Fetching comments for video: Men Vs Women Survive The Wilderness For $500,000\n",
      "Fetching comments for video: Will A Guitar Boat Hold My Weight?\n",
      "Fetching comments for video: Real Or Cake For $10,000\n",
      "Fetching comments for video: 7 Days Stranded In A Cave\n",
      "Fetching comments for video: Running With Bigger And Bigger Feastables\n",
      "Fetching comments for video: Survive 100 Days In Nuclear Bunker, Win $500,000\n",
      "Fetching comments for video: Spot The Fake Animal For $10,000\n",
      "Fetching comments for video: 50 YouTubers Fight For $1,000,000\n",
      "Fetching comments for video: Pass The Phone To…\n",
      "Fetching comments for video: How Many Balloons Does It Take To Fly?\n",
      "Fetching comments for video: I Built 100 Houses And Gave Them Away!\n",
      "Fetching comments for video: World’s Deadliest Obstacle Course!\n",
      "Fetching comments for video: $10,000 Every Day You Survive In The Wilderness\n",
      "Fetching comments for video: Sprinting with More and More Money\n",
      "Fetching comments for video: Giving 1000 Phones Away\n",
      "Fetching comments for video: Bottle Head Smashing World Record Attempt!\n",
      "Fetching comments for video: Protect The Yacht, Keep It!\n",
      "Fetching comments for video: Ages 1-100 Try My Chocolate\n",
      "Fetching comments for video: Spot The Hidden People For $10,000\n",
      "Fetching comments for video: Would You Split Or Steal $250,000?\n",
      "Fetching comments for video: Buy Feastables, Win Unlimited Money\n",
      "Fetching comments for video: In 10 Minutes This Room Will Explode!\n",
      "Fetching comments for video: The World's Fastest Cleaners\n",
      "Fetching comments for video: Ages 1 - 100 Decide Who Wins $250,000\n",
      "Fetching comments for video: Guess The Gift, Keep It\n",
      "Fetching comments for video: I’m Giving My 250M Subscriber $25,000\n",
      "Fetching comments for video: Anything You Touch, You Keep!\n",
      "Fetching comments for video: 7 Days Stranded On An Island\n",
      "Fetching comments for video: Keep Track Of Car, Win $10,000\n",
      "Fetching comments for video: Protect The Lamborghini, Keep It!\n",
      "Fetching comments for video: I Survived 7 Days In An Abandoned City\n",
      "Fetching comments for video: Unboxing My 200M Subscriber Play Button\n",
      "Fetching comments for video: I Filled Chandler’s Car With Feastables\n",
      "Fetching comments for video: Buy Feastables, Win $10,000\n",
      "Fetching comments for video: Face Your Biggest Fear To Win $800,000\n",
      "Fetching comments for video: $1 vs $250,000,000 Private Island!\n",
      "Fetching comments for video: Protect $500,000 Keep It!\n",
      "Fetching comments for video: I Spent 7 Days In Solitary Confinement\n",
      "Fetching comments for video: I Saved 100 Dogs From Dying\n",
      "Fetching comments for video: Survive 100 Days Trapped, Win $500,000\n",
      "Fetching comments for video: Feeding A Dog $1 vs $10,000 Steak\n",
      "Fetching comments for video: Could You Walk Up A Skyscraper?\n",
      "Fetching comments for video: $10,000 Every Day You Survive In A Grocery Store\n",
      "Fetching comments for video: $1 vs $10,000,000 Job!\n",
      "Fetching comments for video: I Spent 7 Days Buried Alive\n",
      "Fetching comments for video: I Gave Away A House On Halloween\n",
      "Fetching comments for video: Giving Car Keys Instead Of Candy On Halloween\n",
      "Fetching comments for video: I Built 100 Wells In Africa\n",
      "Fetching comments for video: Furthest Away From Me Wins $10,000\n",
      "Fetching comments for video: World’s Most Expensive Bed\n",
      "Fetching comments for video: World’s Deadliest Laser Maze!\n",
      "Fetching comments for video: World’s Most Expensive Coffee\n",
      "Fetching comments for video: $100,000,000 Bathroom\n",
      "Fetching comments for video: Miranda Cosgrove Said What?\n",
      "Fetching comments for video: $1 vs $100,000,000 House!\n",
      "Fetching comments for video: I Tipped A Pizza Delivery Driver A Car\n",
      "Fetching comments for video: World's Most Dangerous Trap!\n",
      "Fetching comments for video: I NEED 1 MORE 𝗦𝗨𝗕𝗦𝗖𝗥𝗜𝗕𝗘𝗥\n",
      "Fetching comments for video: Guess The Gift, Keep It\n",
      "Fetching comments for video: Spot The Hidden People For $10,000\n",
      "Fetching comments for video: I Paid A Random Student’s College Tuition\n",
      "Fetching comments for video: $100,000,000 Car Doors\n",
      "Fetching comments for video: $1 vs $100,000,000 Car!\n",
      "Fetching comments for video: Extreme Home Makeover!\n",
      "Fetching comments for video: Katana Vs Bullet\n",
      "Fetching comments for video: How Many School Buses Can We Stack?\n",
      "Fetching comments for video: Lamborghini Vs World's Largest Shredder\n",
      "Fetching comments for video: Feeding A Cat $10 Vs $10,000 Sushi\n",
      "Fetching comments for video: Make This Kick, Win Super Bowl Tickets\n",
      "Fetching comments for video: Metal Pipe Vs School Bus\n",
      "Fetching comments for video: Every Country On Earth Fights For $250,000!\n",
      "Fetching comments for video: Can You Beat A Girl In Arm Wrestling?\n",
      "Fetching comments for video: $1 vs $250,000 Vacation!\n",
      "Fetching comments for video: I Ate The World’s Most Poisonous Fish\n",
      "Fetching comments for video: 7 Days Stranded At Sea\n",
      "Fetching comments for video: I Traded My Car At a Red Light\n",
      "Fetching comments for video: Train Vs Giant Pit\n",
      "Fetching comments for video: I Buried Treasure in the Bermuda Triangle\n",
      "Fetching comments for video: $1 vs $1,000,000,000 Yacht!\n",
      "Fetching comments for video: Do Pawnshops Scam You?\n",
      "Fetching comments for video: Ages 1 - 100 Fight For $500,000\n",
      "Fetching comments for video: I Got Naruto to Subscribe to Me\n",
      "Fetching comments for video: I Made An Egg Sandwich With @BayashiTV_\n",
      "Fetching comments for video: 1,000 Deaf People Hear For The First Time\n",
      "Fetching comments for video: Would You Pet a Cheetah in Africa?\n",
      "Fetching comments for video: Tipping A Waitress A Car\n",
      "Fetching comments for video: Would you go on a Blind Date in Italy?\n",
      "Fetching comments for video: $1 vs $500,000 Plane Ticket!\n",
      "Fetching comments for video: I Sent a Subscriber to Disneyland\n",
      "Fetching comments for video: I Paid A Real Assassin To Try To Kill Me\n",
      "Fetching comments for video: Do Men Lie About Their Height?\n",
      "Fetching comments for video: 1,000 Blind People See For The First Time\n",
      "Fetching comments for video: I Survived 50 Hours In Antarctica\n",
      "Fetching comments for video: Hydraulic Press Vs Lamborghini\n",
      "Fetching comments for video: Would You Fly To Paris For A Baguette?\n",
      "Fetching comments for video: 100 Kids Vs 100 Adults For $500,000\n",
      "Fetching comments for video: Gordon Ramsay Tries Most Expensive Chocolate Bar!\n",
      "Fetching comments for video: Last To Take Hand Off Jet, Keeps It!\n",
      "Data saved to MrBeast_video_comments.csv\n",
      "Execution time: -13.635357856750488\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fetch_videos_and_comments_opti' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution time:\u001b[39m\u001b[38;5;124m\"\u001b[39m,execution_time)\n\u001b[1;32m      9\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mfetch_videos_and_comments_opti\u001b[49m(channel_id, max_videos\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_comments_per_video\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     11\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m start_time \u001b[38;5;241m-\u001b[39m end_time\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fetch_videos_and_comments_opti' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# Replace with the actual YouTube channel ID\n",
    "channel_id = f'UCX6OQ3DkcsbYNE6H8uQQuVA'\n",
    "fetch_videos_and_comments(channel_id, max_videos=100, max_comments_per_video=100)\n",
    "end_time = time.time()\n",
    "execution_time = start_time - end_time\n",
    "print(\"Execution time:\",execution_time)\n",
    "start_time = time.time()\n",
    "fetch_videos_and_comments_opti(channel_id, max_videos=100, max_comments_per_video=100)\n",
    "end_time = time.time()\n",
    "execution_time = start_time - end_time\n",
    "print(\"Execution time:\",execution_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
